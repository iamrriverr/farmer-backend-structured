# src/domain/chat/service.py
"""
èŠå¤©æ¥­å‹™é‚è¼¯å±¤ (Service)
è™•ç†èŠå¤©ç›¸é—œçš„æ¥­å‹™é‚è¼¯ï¼Œå”èª¿ Repositoryã€RAG Engine èˆ‡å¤–éƒ¨æœå‹™
"""

from typing import Dict, Optional, List, AsyncGenerator
from fastapi import HTTPException, status
from .repository import ChatRepository
from .schemas import ChatRequest, ChatResponse, ChatSource, IntentResult
from .rag_engine import RAGEngine
from .intent_classifier import IntentClassifier


class ChatService:
    """èŠå¤©æ¥­å‹™é‚è¼¯é¡åˆ¥"""
    
    def __init__(self, repository: ChatRepository, rag_engine: RAGEngine,
                 intent_classifier: IntentClassifier):
        """
        åˆå§‹åŒ– Service
        
        Args:
            repository: ChatRepository å¯¦ä¾‹
            rag_engine: RAG å¼•æ“
            intent_classifier: æ„åœ–åˆ†é¡å™¨
        """
        self.repo = repository
        self.rag = rag_engine
        self.classifier = intent_classifier
    
    def process_query(self, request: ChatRequest, user_id: int) -> ChatResponse:
        """
        è™•ç†èŠå¤©æŸ¥è©¢ï¼ˆREST APIï¼‰
        
        Args:
            request: èŠå¤©è«‹æ±‚
            user_id: ç”¨æˆ¶ ID
            
        Returns:
            ChatResponse: èŠå¤©å›æ‡‰
        """
        # æ„åœ–åˆ†é¡
        intent_result = self.classifier.classify(request.question)
        
        # è¼‰å…¥å°è©±æ­·å²
        history_context = ""
        if request.conversation_id:
            history = self.repo.get_recent_history(request.conversation_id, limit=10)
            if history:
                history_context = self._format_history(history)
        
        # æ ¹æ“šæ„åœ–æ±ºå®šè™•ç†æ–¹å¼
        if intent_result["type"] == "out_of_scope":
            answer = self._handle_out_of_scope()
            sources = []
        elif intent_result["use_rag"]:
            answer, sources = self._process_with_rag(
                request.question, history_context, request.k
            )
        else:
            answer = self._process_chitchat(request.question, history_context)
            sources = []
        
        # å„²å­˜å°è©±è¨˜éŒ„
        if request.conversation_id:
            self.repo.save_message(request.conversation_id, "user", request.question)
            self.repo.save_message(
                request.conversation_id, "assistant", answer,
                sources=[s.dict() for s in sources],
                intent=intent_result
            )
            self.repo.update_conversation_stats(request.conversation_id, user_id)
        
        return ChatResponse(
            answer=answer,
            sources=sources,
            context_count=len(sources),
            conversation_id=request.conversation_id,
            intent=intent_result
        )
    
    async def process_streaming_query(self, request: ChatRequest, 
                                      user_id: int) -> AsyncGenerator[Dict, None]:
        """
        è™•ç†ä¸²æµèŠå¤©æŸ¥è©¢
        
        Args:
            request: èŠå¤©è«‹æ±‚
            user_id: ç”¨æˆ¶ ID
            
        Yields:
            Dict: ä¸²æµå›æ‡‰ç‰‡æ®µ
        """
        # æ„åœ–åˆ†é¡
        intent_result = self.classifier.classify(request.question)
        yield {"type": "intent", "data": intent_result}
        
        # è¼‰å…¥å°è©±æ­·å²
        history_context = ""
        if request.conversation_id:
            history = self.repo.get_recent_history(request.conversation_id, limit=10)
            if history:
                history_context = self._format_history(history)
        
        # ä¸²æµç”Ÿæˆå›ç­”
        full_response = ""
        sources = []
        
        if intent_result["type"] == "out_of_scope":
            answer = self._handle_out_of_scope()
            for char in answer:
                yield {"type": "chunk", "content": char}
                full_response += char
        elif intent_result["use_rag"]:
            async for chunk in self.rag.generate_stream(
                request.question, history_context, request.k
            ):
                if chunk["type"] == "chunk":
                    full_response += chunk["content"]
                elif chunk["type"] == "sources":
                    sources = chunk["sources"]
                yield chunk
        else:
            async for chunk in self.rag.generate_chitchat_stream(
                request.question, history_context
            ):
                full_response += chunk["content"]
                yield chunk
        
        # å„²å­˜å°è©±è¨˜éŒ„
        if request.conversation_id:
            self.repo.save_message(request.conversation_id, "user", request.question)
            self.repo.save_message(
                request.conversation_id, "assistant", full_response,
                sources=sources, intent=intent_result
            )
            self.repo.update_conversation_stats(request.conversation_id, user_id)
        
        yield {"type": "done", "sources": sources}
    
    def get_conversation_history(self, conversation_id: str, user_id: int,
                                limit: int = 100, offset: int = 0) -> List[Dict]:
        """
        å–å¾—å°è©±æ­·å²
        
        Args:
            conversation_id: å°è©± ID
            user_id: ç”¨æˆ¶ ID
            limit: è¿”å›æ•¸é‡é™åˆ¶
            offset: åˆ†é åç§»é‡
            
        Returns:
            List[Dict]: èŠå¤©è¨˜éŒ„
        """
        messages = self.repo.get_chat_history(conversation_id, limit, offset)
        
        # æ ¼å¼åŒ–å›æ‡‰
        formatted_messages = []
        for msg in messages:
            formatted_messages.append({
                "role": msg["role"],
                "content": msg["content"],
                "timestamp": msg["created_at"].isoformat(),
                "sources": msg.get("sources"),
                "intent": msg.get("intent")
            })
        
        return formatted_messages
    
    def clear_conversation_history(self, conversation_id: str, user_id: int):
        """
        æ¸…ç©ºå°è©±æ­·å²
        
        Args:
            conversation_id: å°è©± ID
            user_id: ç”¨æˆ¶ ID
        """
        self.repo.clear_chat_history(conversation_id)
    
    def _format_history(self, history: List[tuple]) -> str:
        """æ ¼å¼åŒ–å°è©±æ­·å²ç‚ºæ–‡å­—"""
        formatted = "\nã€æ­·å²å°è©±ã€‘\n"
        for role, content in history:
            prefix = "ç”¨æˆ¶" if role == "user" else "AI"
            formatted += f"{prefix}: {content}\n"
        return formatted + "\n"
    
    def _handle_out_of_scope(self) -> str:
        """è™•ç†è¶…å‡ºç¯„åœçš„å•é¡Œ"""
        return """æŠ±æ­‰ï¼Œé€™å€‹å•é¡Œè¶…å‡ºäº†æˆ‘çš„æœå‹™ç¯„åœã€‚ğŸ˜Š

æˆ‘ä¸»è¦å”åŠ©ä»¥ä¸‹é ˜åŸŸçš„å•é¡Œï¼š
â€¢ ğŸŒ¾ è¾²æ¥­æŠ€è¡“è«®è©¢ï¼ˆç¨®æ¤ã€ç—…èŸ²å®³ã€æ–½è‚¥ç­‰ï¼‰
â€¢ ğŸ’° è¾²æ¥­æ”¿ç­–èˆ‡è£œåŠ©ç”³è«‹
â€¢ ğŸ“‹ è¾²æœƒç›¸é—œæ¥­å‹™æŸ¥è©¢
â€¢ ğŸ” è¾²æ¥­æ–‡ä»¶è³‡æ–™æŸ¥è©¢

æ‚¨å¯ä»¥æ›å€‹èˆ‡è¾²æ¥­ç›¸é—œçš„å•é¡Œè©¦è©¦çœ‹ï¼"""
    
    def _process_with_rag(self, question: str, history: str, k: int) -> tuple:
        """ä½¿ç”¨ RAG è™•ç†å•é¡Œ"""
        result = self.rag.query(question, history, k)
        sources = [
            ChatSource(
                source=doc["source"],
                department=doc.get("department", ""),
                content=doc["content"]
            )
            for doc in result.get("sources", [])
        ]
        return result["answer"], sources
    
    def _process_chitchat(self, question: str, history: str) -> str:
        """è™•ç†é–’èŠ"""
        return self.rag.chitchat(question, history)
